# 2. Open-Source LLMs

In the previous module, we used Gemini 1.5 Flash via Google API. It's a very convenient way to use an LLM, but you have to pay for the usage, and you don't have control over the model you get to use.

In this module, we'll look at using open-source LLMs instead.

## 2.1 Introduction

YouTube Class: [2.1 - Introduction to Open-Source](https://www.youtube.com/watch?v=ATchkIRsH4g&list=PL3MmuxUbc_hIB4fSqLy_0AfTjVLpgjV3R)

* Open-Source LLMs
* Replacing the LLM box in the RAG flow

## 2.2 Using a GPU in Saturn Cloud

YouTube Class: [2.2 - Using SaturnCloud for GPU Notebooks](https://www.youtube.com/watch?v=E0cAqBWfJYY&list=PL3MmuxUbc_hIB4fSqLy_0AfTjVLpgjV3R&index=9)

* Registering in Saturn Cloud
* Configuring secrets and git
* Creating an instance with a GPU

Bonus: [Using Google Colab for GPU Notebooks](https://www.loom.com/share/591f39e4e231486bbfc3fbd316ec03c5)
> *This is my personal choice!*

## 2.3 Model: Google FLAN-T5

YouTube Class: [2.3 - HuggingFace and Google FLAN T5](https://www.youtube.com/watch?v=a86iTyxnFE4&list=PL3MmuxUbc_hIB4fSqLy_0AfTjVLpgjV3R&index=10)

* Model: `google/flan-t5-xl`
* Notebook: [huggingface-flan-t5.ipynb](huggingface-flan-t5.ipynb)


